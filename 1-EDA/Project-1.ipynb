{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Project 1 - Exploratory Data Analysis for Machine Learning\n",
    "This notebook is a part of my first project required by IBM Machine Learning Program.\n",
    "\n",
    "Data source: [Board Games - Tidy Tuesday](https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-03-12)\n",
    "\n",
    "In this notebook, I will clean the data and explore the relationship between the target (game average rating) and potential predictors. I will also construct new features from the existing data when possible and perform hypothesis tests.\n",
    "\n",
    "Notebook Contents:\n",
    "> 1. Data Overview\n",
    "> 2. Data Cleaning and Feature Engineering: Categorical Data\n",
    "> 3. Data Cleaning and Feature Engineering: Numeric Data\n",
    "> 4. Hypothesis Testing\n",
    "\n",
    "## 1. Data Overview"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%pylab inline\n",
    "%config InlineBackend.figure_formats = ['retina']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the dataset\n",
    "data = pd.read_csv(r'C:\\Users\\Thanh Huynh\\Documents\\Projects\\github\\IBM-Machine-Learning\\data\\board_games.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First look\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine columns\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine missing data\n",
    "train.isnull().sum().sort_values()"
   ]
  },
  {
   "source": [
    "There are missing data only in some of the categorical data. Let's clean those first.\n",
    "## 2. Data Cleaning and Feature Engineering: Categorical Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at all categorical variables\n",
    "train.describe(include='object').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep original data\n",
    "df = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove features that have too many missing values or those that can't help discriminate the target\n",
    "df.drop(['game_id', 'description', 'image', 'name',\n",
    "         'thumbnail', 'family', 'expansion', 'compilation'],\n",
    "         axis=1, inplace=True)"
   ]
  },
  {
   "source": [
    "### Counts derived from category aggregates"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select categorical variable names\n",
    "category_cols = df.select_dtypes(np.object).columns\n",
    "\n",
    "# Iterate through each column and count unique values\n",
    "for cat in category_cols:\n",
    "    num_unique_values = len(set(','.join(df[cat].dropna()).replace(', ', ',').split(',')))\n",
    "    print(f'Number of unique values of {cat}:\\t\\t{num_unique_values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count values in each categorical variable of each game\n",
    "for cat in category_cols:\n",
    "    df['num_' + cat] = [np.nan if x is np.nan \n",
    "                               else len(x) + 1 \n",
    "                               for x in df[cat].str.findall(',')]\n",
    "\n",
    "# Drop multi-level categorical variables\n",
    "df.drop(['artist', 'designer', 'publisher'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows that have missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Current data shape\n",
    "df.shape"
   ]
  },
  {
   "source": [
    "Within a row, each categorical variable contains multiple values. I will transform these data to dummies.\n",
    "### Categories derived from category aggregates\n",
    "\n",
    "- Get a set of all unique values in each variable\n",
    "- Create new columns based on these values\n",
    "- Iterate through all rows and fill in dummy values for each new column\n",
    "- Group these dummy variables if possible "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create functions\n",
    "def value_list(data: pd.DataFrame, col: str) -> list:\n",
    "    \"\"\" Returns a list of unique values that included in a given column\n",
    "    \"\"\"\n",
    "    # Join all values in the column then get a set of them\n",
    "    value_set = set(','.join(df[col].dropna()).replace(', ', ',').split(','))\n",
    "\n",
    "    # Make all string lower case for processing purpose\n",
    "    repr_list = [x.lower() for x in list(value_set)]\n",
    "\n",
    "    return repr_list\n",
    "\n",
    "def create_dummies(data: pd.DataFrame, col: str, key_word: str) -> list:\n",
    "    \"\"\" Creates dummies for a given category in a column\n",
    "    \"\"\"\n",
    "    word_list = [1 if (x is not np.nan) and (key_word in str(x).lower())\n",
    "                 else 0 if (x is not np.nan) and (key_word not in str(x).lower())\n",
    "                 else np.nan for x in data[col]]\n",
    "    return word_list\n",
    "\n",
    "\n",
    "def dummy_loop(data: pd.DataFrame, col: str) -> pd.DataFrame:\n",
    "    \"\"\" Returns a data frame of dummies \n",
    "    \"\"\"\n",
    "    # Iterate through columns\n",
    "    for value in value_list(data, col):\n",
    "        data[col + '_' + value] = create_dummies(data=data, col=col, key_word=value)\n",
    "    \n",
    "    # Drop the original columns\n",
    "    data.drop(col, axis=1, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out game categories\n",
    "value_list(df, 'category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out game mechanics\n",
    "value_list(df, 'mechanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply functions to get dummies\n",
    "df = dummy_loop(dummy_loop(df, 'category'), 'mechanic')\n",
    "\n",
    "# Print out first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current data shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of game categories\n",
    "game_categories = df.filter(regex='^category_', axis=1)\n",
    "game_categories.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group categories based on BGG wiki\n",
    "activity_categories = ['category_city building', 'category_civilization',\n",
    "                       'category_educational', 'category_puzzle',\n",
    "                       'category_racing', 'category_territory building',\n",
    "                       'category_transportation']\n",
    "\n",
    "component_categories = ['category_card game', 'category_collectible components',\n",
    "                        'category_dice', 'category_electronic',\n",
    "                        'category_miniatures']\n",
    "\n",
    "nongame_categories = ['category_book', 'category_expansion for base-game',\n",
    "                      'category_game system']\n",
    "\n",
    "war_categories = list(df.filter(regex='war', axis=1).columns)\n",
    "war_categories = war_categories + ['category_napoleonic', 'category_post-napoleonic',\n",
    "                                   'category_pike and shot']\n",
    "\n",
    "skills_categories = ['category_action / dexterity', 'category_bluffing',\n",
    "                     'category_deduction', 'category_economic',\n",
    "                     'category_math', 'category_number',\n",
    "                     'category_memory', 'category_negotiation',\n",
    "                     'category_real-time', 'category_spatial analysis',\n",
    "                     'category_trivia', 'category_word game']\n",
    "\n",
    "entertainment_categories = ['category_comic book / strip', 'category_movies / tv / radio theme',\n",
    "                            'category_music', 'category_novel-based',\n",
    "                            'category_video game theme']\n",
    "\n",
    "nongroup_categories = ['category_party game', 'category_abstract strategy',\n",
    "                       \"category_children's game\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create functions\n",
    "def dummy_group(data: pd.DataFrame, category: list) -> list:\n",
    "    \"\"\"\n",
    "    Returns a list of dummies derived from input category\n",
    "    \"\"\"\n",
    "    for i in category:\n",
    "        if i not in list(data.columns):\n",
    "            category.remove(i)\n",
    "    dummies = [1 if x >= 1 else 0 for x in data[category].sum(axis=1)]\n",
    "    data.drop(category, axis=1, inplace=True)\n",
    "    return dummies\n",
    "\n",
    "def plot_bar(data: pd.DataFrame,\n",
    "             prefix: str, figsize: tuple,\n",
    "             title: str):\n",
    "    category_df = (df\n",
    "                   .filter(regex=prefix, axis=1)\n",
    "                   .sum()\n",
    "                   .to_frame('count')\n",
    "                   .sort_values('count')\n",
    "    )\n",
    "    ax = category_df.plot.barh(legend=None, figsize=figsize, linewidth=0)\n",
    "    ax.set_yticklabels(list(category_df.sort_values('count').index.str.replace(prefix,'')), fontsize=7)\n",
    "    ax.tick_params(axis='x', labelsize=7)\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply dummy function to each category\n",
    "df['category_activity'] = dummy_group(df, activity_categories)\n",
    "df['category_component'] = dummy_group(df, component_categories)\n",
    "df['category_nongame'] = dummy_group(df, nongame_categories)\n",
    "df['category_war'] = dummy_group(df, war_categories)\n",
    "df['category_skills'] = dummy_group(df, skills_categories)\n",
    "df['category_entertainment'] = dummy_group(df, entertainment_categories)\n",
    "\n",
    "# Select games only\n",
    "df = df[df['category_nongame'] == 0]\n",
    "df.drop('category_nongame', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bar(data=df,\n",
    "         prefix='category_',\n",
    "         figsize=(8,6),\n",
    "         title='Number of Games by Category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bar(data=df,\n",
    "         prefix='mechanic_',\n",
    "         figsize=(8,6),\n",
    "         title='Number of Games by Mechanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current data shape\n",
    "df.shape"
   ]
  },
  {
   "source": [
    "## 3. Data Cleaning and Engineering: Numeric Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric data that are not binary\n",
    "numeric_df = df.loc[:, ~df.isin([0,1]).all()]\n",
    "numeric_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some statistics\n",
    "numeric_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select non zero rows only\n",
    "df = df[(df.iloc[:,:6] > 0).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create game age variable from year published\n",
    "df['game_age'] = 2019 - df['year_published']\n",
    "\n",
    "# Drop unuseful columns\n",
    "df.drop(['max_playtime', 'min_playtime', 'users_rated'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data again\n",
    "numeric_df = df.loc[:, ~df.isin([0,1]).all()]\n",
    "\n",
    "# Current data shape\n",
    "numeric_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check statistics again\n",
    "numeric_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a functions to plot multiple bar charts\n",
    "def hist_loop(data: pd.DataFrame,\n",
    "              rows: int,\n",
    "              cols: int,\n",
    "              figsize: tuple):\n",
    "    fig, axes = plt.subplots(rows,cols, figsize=figsize)\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        if i < len(data.columns):\n",
    "            data[sorted(data.columns)[i]].plot.hist(bins=30, ax=ax)\n",
    "            ax.set_title(f'{sorted(data.columns)[i]} distribution', fontsize=7)\n",
    "            ax.tick_params(axis='x', labelsize=7)\n",
    "            ax.tick_params(axis='y', labelsize=7)\n",
    "            ax.get_yaxis().get_label().set_visible(False)\n",
    "        else:\n",
    "            fig.delaxes(ax=ax)\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_loop(data=numeric_df,\n",
    "          rows=3,\n",
    "          cols=4,\n",
    "          figsize=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to check skewness\n",
    "def skew_df(data: pd.DataFrame, skew_limit: float) -> pd.DataFrame:\n",
    "    # Define a limit above which we will log transform\n",
    "    skew_vals = data.skew()\n",
    "\n",
    "    # Showing the skewed columns\n",
    "    skew_cols = (skew_vals\n",
    "                 .sort_values(ascending=False)\n",
    "                 .to_frame('Skew')\n",
    "                 .query('abs(Skew) > {}'.format(skew_limit))\n",
    "    )\n",
    "    return skew_cols"
   ]
  },
  {
   "source": [
    "# Print out skewed columns\n",
    "skew_cols = skew_df(numeric_df, 0.75)\n",
    "skew_cols"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "### Log transformation for skewed variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Perform log transformation\n",
    "for col in skew_cols.index.values:\n",
    "    numeric_df['log_' + col] = numeric_df[col].apply(np.log1p)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check skewness on log transformed data\n",
    "log_df = numeric_df.filter(regex='^log_', axis=1)\n",
    "skew_log_cols = skew_df(log_df, 0.75)\n",
    "skew_log_cols"
   ]
  },
  {
   "source": [
    "# Plot log columns that have nearly normal distribution\n",
    "log_df.drop(skew_log_cols.index, axis=1, inplace=True)\n",
    "hist_loop(data=log_df,\n",
    "          rows=3,\n",
    "          cols=4,\n",
    "          figsize=(12,6))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join these new columns to our dataset\n",
    "df = df.join(log_df).drop([x.replace('log_', '') for x in log_df.columns], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot of numeric data\n",
    "sns.pairplot(data=df, vars=['min_age', 'log_game_age', 'log_min_players', 'log_num_category',\n",
    "                            'log_num_mechanic', 'log_playing_time', 'average_rating'],\n",
    "             plot_kws=dict(alpha=.2, edgecolor='none'));"
   ]
  },
  {
   "source": [
    "Observations from this plot:\n",
    "- The target (average_rating) has a normal distribution.\n",
    "- No strong linear relationship between the features and the target. Linear regression might not be well-suited to this problem.\n",
    "- There might be a relationship between minimum age and playing time.\n",
    "- I can try adding polynomial and interaction terms and examine their correlation with the target.\n",
    "\n",
    "### Adding polynomial and interaction terms"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Instantiate and provide desired degree; \n",
    "# Note: degree=2 also includes intercept, degree 1 terms, and cross-terms\n",
    "pf = PolynomialFeatures(degree=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features\n",
    "feature_cols = ['min_age', 'log_game_age', 'log_min_players', 'log_num_category',\n",
    "                'log_num_mechanic', 'log_playing_time']\n",
    "features = df[feature_cols]\n",
    "\n",
    "# fit and transform\n",
    "pf.fit(features)\n",
    "feat_array = pf.transform(features)\n",
    "\n",
    "# Create a data frame\n",
    "feat_df = pd.DataFrame(feat_array,\n",
    "                       index=df.index,\n",
    "                       columns=pf.get_feature_names(input_features=features.columns))\n",
    "\n",
    "# Drop the intercept\n",
    "feat_df.drop('1', axis=1, inplace=True)\n",
    "\n",
    "# Add in the target\n",
    "feat_df.insert(0, 'average_rating', df['average_rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a heatmap of correlations\n",
    "with sns.axes_style('white'):\n",
    "    fig, axes = plt.subplots(figsize=(8,8))\n",
    "    mask = np.triu(np.ones_like(feat_df.corr(), dtype=bool))\n",
    "    sns.heatmap(feat_df.corr(),\n",
    "                mask=mask,\n",
    "                cmap='binary',\n",
    "                cbar=False,\n",
    "                annot=True,\n",
    "                annot_kws={'size':6},\n",
    "                fmt='.2f')\n",
    "    plt.title('Polynomial Features and Their Correlations')\n",
    "    plt.tick_params(axis='x', labelsize=8)\n",
    "    plt.tick_params(axis='y', labelsize=8)"
   ]
  },
  {
   "source": [
    "This plot shows that polynomial and interaction terms do not have significantly higher correlations with the target comparing to the original features."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join these new columns to our dataset\n",
    "for col in feat_df.columns:\n",
    "    if col in df.columns:\n",
    "        feat_df.drop(col, axis=1, inplace=True)\n",
    "df = df.join(feat_df)"
   ]
  },
  {
   "source": [
    "### Binning numeric data\n",
    "\n",
    "- Binning numeric data that cannot be scaled by log transformation\n",
    "- Dummy transformation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of artists\n",
    "pd.qcut(df['num_artist'], q=4, duplicates='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['group_artist'] = pd.qcut(df['num_artist'],\n",
    "                             q=4,\n",
    "                             duplicates='drop',\n",
    "                             labels=['two_or_less', 'three_or_more'])\n",
    "df.drop('num_artist', axis=1, inplace=True)\n",
    "df = pd.get_dummies(df, columns=['group_artist'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of designers\n",
    "pd.qcut(df['num_designer'], q=4, duplicates='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['group_designer'] = pd.qcut(df['num_designer'],\n",
    "                               q=4,\n",
    "                               duplicates='drop',\n",
    "                               labels=['two_or_less', 'three_or_more'])\n",
    "df.drop('num_designer', axis=1, inplace=True)\n",
    "df = pd.get_dummies(df, columns=['group_designer'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of publishers\n",
    "pd.qcut(df['num_publisher'], q=4, duplicates='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.qcut(df['num_publisher'], q=3, duplicates='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['group_publisher'] = pd.qcut(df['num_publisher'],\n",
    "                                q=3,\n",
    "                                duplicates='drop',\n",
    "                                labels=['three_or_less', 'four_or_more'])\n",
    "df.drop('num_publisher', axis=1, inplace=True)\n",
    "df = pd.get_dummies(df, columns=['group_publisher'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of maximum players\n",
    "pd.qcut(df['max_players'], q=4, duplicates='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['group_max_players'] = pd.qcut(df['max_players'],\n",
    "                                  q=4,\n",
    "                                  duplicates='drop',\n",
    "                                  labels=['four_or_less', 'five_or_six', 'seven_or_more'])\n",
    "df.drop('max_players', axis=1, inplace=True)\n",
    "df = pd.get_dummies(df, columns=['group_max_players'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year published\n",
    "pd.qcut(df['year_published'], q=4, duplicates='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['group_year_published'] = pd.qcut(df['year_published'],\n",
    "                                     q=4,\n",
    "                                     duplicates='drop',\n",
    "                                     labels=['before_2001', 'between_2001_and_2009', 'between_2010_and_2013', 'between_2014_and_2016'])\n",
    "df.drop('year_published', axis=1, inplace=True)\n",
    "df = pd.get_dummies(df, columns=['group_year_published'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "source": [
    "## 4. Hypothesis Testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to conduct Welch's test and plot distributions\n",
    "def t_ind_test(s1: pd.Series,\n",
    "               s2: pd.Series,\n",
    "               equal_var=False) -> tuple:\n",
    "    \"\"\"\n",
    "    Returns t-value and p-value\n",
    "    \"\"\"\n",
    "\n",
    "    dfreedom = len(s1) + len(s2) - 2\n",
    "    t_val, p_val = ttest_ind(s1, s2, equal_var=equal_var)\n",
    "    return t_val, p_val\n",
    "\n",
    "def test_loop(data: pd.DataFrame,\n",
    "              prefix: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a table of t test result sorted by p-values \n",
    "    with colored bars (green for positive values and red for negative ones)\n",
    "    \"\"\"\n",
    "\n",
    "    category_df = data.filter(regex=prefix, axis=1)\n",
    "    category = sorted(list(category_df.columns))\n",
    "\n",
    "    test_results = []\n",
    "    for i in category:\n",
    "        non_category_ratings = data[data[i] == 0]['average_rating']\n",
    "        category_ratings = data[data[i] == 1]['average_rating']\n",
    "        test_results.append((i.replace(prefix, ''),) + t_ind_test(category_ratings, non_category_ratings))\n",
    "\n",
    "    test_results_df = (pd.DataFrame(test_results, columns=[prefix + 'name', 't-value', 'p-value'])\n",
    "                       .sort_values('p-value')\n",
    "                       .set_index(prefix + 'name')\n",
    "    )\n",
    "    test_results_df = test_results_df.style.bar(align='mid', color=['#d65f5f', '#5fba7d'])\n",
    "    return test_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loop(df, 'category_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loop(df, 'mechanic_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loop(df, 'group_')"
   ]
  }
 ]
}